{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.2 (default, Jul 29 2017, 00:00:00) \n",
      "[GCC 4.8.4]; CUDA Version: 8.0.61; pytorch version: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as vision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "torch.cuda.set_device(0)\n",
    "print('Python Version: {}; CUDA Version: {}; pytorch version: {}'.format(\n",
    "    sys.version,torch.version.cuda,torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change the PIL to tensor\n",
    "from torchvision.transforms import ToTensor, Normalize as Norm, Compose\n",
    "transform = Compose([ToTensor(),Norm((0.5,), (0.5,))]) # mean, range (change to 0 - 1)\n",
    "\n",
    "train_dataset = MNIST(root='../dataset/MNIST',train=True,download=True,transform=transform)\n",
    "test_dataset = MNIST(root='../dataset/MNIST',train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build up the dataset from numpy array\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from torch.utils.data import TensorDataset as TData\n",
    "import numpy as np\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X_train, X_test, y_train, y_test = split(mnist['data'],mnist['target'],train_size=60000,test_size=10000)\n",
    "norm = Normalizer()\n",
    "X_train = norm.fit_transform(X_train).astype(np.float32)\n",
    "X_test = norm.transform(X_test).astype(np.float32)\n",
    "train_dataset = TData(torch.from_numpy(X_train.reshape((-1,1,28,28)),), \n",
    "                      torch.from_numpy(y_train.astype(np.long)).view(-1))\n",
    "test_dataset =  TData(torch.from_numpy(X_test.reshape((-1,1,28,28))), \n",
    "                      torch.from_numpy(y_test.astype(np.long)).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print (len(train_dataset)) # length method\n",
    "print (train_dataset[0][0].shape) # Data field, channel * width * length for conv2\n",
    "print (train_dataset[0][1].shape) # Label field, .view(-1)\n",
    "train_feeder = DataLoader(train_dataset, batch_size=128,shuffle=True, num_workers=2)\n",
    "test_feeder = DataLoader(test_dataset,batch_size=1024,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d as Conv, MaxPool2d as Pool, Linear as FC\n",
    "from torch.nn.functional import relu, dropout\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = Conv(1, 6, kernel_size=5)\n",
    "        self.pool = Pool(2, 2)\n",
    "        self.conv2 = Conv(6, 16, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = FC(16 * 4 * 4, 120)\n",
    "        self.fc2 = FC(120, 84)\n",
    "        self.fc3 = FC(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(relu(self.conv1(x)))\n",
    "        x = self.pool(relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4) # in pytorch: need to view to reshape\n",
    "        x = relu(self.fc1(x))\n",
    "        x = relu(self.fc2(x))\n",
    "        x = dropout(x,training=self.training)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0: Train set: Average loss: 0.0180, Accuracy: 6601/60000 (11.00%)\n",
      "Epoch = 1: Train set: Average loss: 0.0180, Accuracy: 6937/60000 (11.56%)\n",
      "Epoch = 2: Train set: Average loss: 0.0117, Accuracy: 28412/60000 (47.35%)\n",
      "Epoch = 3: Train set: Average loss: 0.0037, Accuracy: 51292/60000 (85.49%)\n",
      "Epoch = 4: Train set: Average loss: 0.0021, Accuracy: 55155/60000 (91.92%)\n",
      "Epoch = 5: Train set: Average loss: 0.0015, Accuracy: 56560/60000 (94.27%)\n",
      "Epoch = 6: Train set: Average loss: 0.0012, Accuracy: 57316/60000 (95.53%)\n",
      "Epoch = 7: Train set: Average loss: 0.0010, Accuracy: 57785/60000 (96.31%)\n",
      "Epoch = 8: Train set: Average loss: 0.0009, Accuracy: 58041/60000 (96.73%)\n",
      "Epoch = 9: Train set: Average loss: 0.0008, Accuracy: 58223/60000 (97.04%)\n",
      "Epoch = 10: Train set: Average loss: 0.0007, Accuracy: 58447/60000 (97.41%)\n",
      "Epoch = 11: Train set: Average loss: 0.0007, Accuracy: 58515/60000 (97.53%)\n",
      "Epoch = 12: Train set: Average loss: 0.0006, Accuracy: 58675/60000 (97.79%)\n",
      "Epoch = 13: Train set: Average loss: 0.0006, Accuracy: 58796/60000 (97.99%)\n",
      "Epoch = 14: Train set: Average loss: 0.0005, Accuracy: 58841/60000 (98.07%)\n",
      "Epoch = 15: Train set: Average loss: 0.0005, Accuracy: 58912/60000 (98.19%)\n",
      "Epoch = 16: Train set: Average loss: 0.0005, Accuracy: 58940/60000 (98.23%)\n",
      "Epoch = 17: Train set: Average loss: 0.0004, Accuracy: 59030/60000 (98.38%)\n",
      "Epoch = 18: Train set: Average loss: 0.0004, Accuracy: 59108/60000 (98.51%)\n",
      "Epoch = 19: Train set: Average loss: 0.0004, Accuracy: 59132/60000 (98.55%)\n",
      "Epoch = 20: Train set: Average loss: 0.0004, Accuracy: 59164/60000 (98.61%)\n",
      "Epoch = 21: Train set: Average loss: 0.0004, Accuracy: 59196/60000 (98.66%)\n",
      "Epoch = 22: Train set: Average loss: 0.0003, Accuracy: 59282/60000 (98.80%)\n",
      "Epoch = 23: Train set: Average loss: 0.0003, Accuracy: 59275/60000 (98.79%)\n",
      "Epoch = 24: Train set: Average loss: 0.0003, Accuracy: 59321/60000 (98.87%)\n",
      "Epoch = 25: Train set: Average loss: 0.0003, Accuracy: 59312/60000 (98.85%)\n",
      "Epoch = 26: Train set: Average loss: 0.0003, Accuracy: 59370/60000 (98.95%)\n",
      "Epoch = 27: Train set: Average loss: 0.0003, Accuracy: 59367/60000 (98.94%)\n",
      "Epoch = 28: Train set: Average loss: 0.0003, Accuracy: 59413/60000 (99.02%)\n",
      "Epoch = 29: Train set: Average loss: 0.0003, Accuracy: 59414/60000 (99.02%)\n",
      "Epoch = 30: Train set: Average loss: 0.0002, Accuracy: 59421/60000 (99.03%)\n",
      "Epoch = 31: Train set: Average loss: 0.0002, Accuracy: 59467/60000 (99.11%)\n",
      "Epoch = 32: Train set: Average loss: 0.0002, Accuracy: 59472/60000 (99.12%)\n",
      "Epoch = 33: Train set: Average loss: 0.0002, Accuracy: 59503/60000 (99.17%)\n",
      "Epoch = 34: Train set: Average loss: 0.0002, Accuracy: 59484/60000 (99.14%)\n",
      "Epoch = 35: Train set: Average loss: 0.0002, Accuracy: 59543/60000 (99.24%)\n",
      "Epoch = 36: Train set: Average loss: 0.0002, Accuracy: 59539/60000 (99.23%)\n",
      "Epoch = 37: Train set: Average loss: 0.0002, Accuracy: 59547/60000 (99.25%)\n",
      "Epoch = 38: Train set: Average loss: 0.0002, Accuracy: 59572/60000 (99.29%)\n",
      "Epoch = 39: Train set: Average loss: 0.0002, Accuracy: 59570/60000 (99.28%)\n",
      "Epoch = 40: Train set: Average loss: 0.0002, Accuracy: 59594/60000 (99.32%)\n",
      "Epoch = 41: Train set: Average loss: 0.0002, Accuracy: 59628/60000 (99.38%)\n",
      "Epoch = 42: Train set: Average loss: 0.0002, Accuracy: 59597/60000 (99.33%)\n",
      "Epoch = 43: Train set: Average loss: 0.0001, Accuracy: 59633/60000 (99.39%)\n",
      "Epoch = 44: Train set: Average loss: 0.0002, Accuracy: 59608/60000 (99.35%)\n",
      "Epoch = 45: Train set: Average loss: 0.0002, Accuracy: 59622/60000 (99.37%)\n",
      "Epoch = 46: Train set: Average loss: 0.0001, Accuracy: 59709/60000 (99.52%)\n",
      "Epoch = 47: Train set: Average loss: 0.0001, Accuracy: 59641/60000 (99.40%)\n",
      "Epoch = 48: Train set: Average loss: 0.0001, Accuracy: 59672/60000 (99.45%)\n",
      "Epoch = 49: Train set: Average loss: 0.0001, Accuracy: 59687/60000 (99.48%)\n",
      "Epoch = 50: Train set: Average loss: 0.0001, Accuracy: 59681/60000 (99.47%)\n",
      "Epoch = 51: Train set: Average loss: 0.0001, Accuracy: 59717/60000 (99.53%)\n",
      "Epoch = 52: Train set: Average loss: 0.0001, Accuracy: 59723/60000 (99.54%)\n",
      "Epoch = 53: Train set: Average loss: 0.0001, Accuracy: 59718/60000 (99.53%)\n",
      "Epoch = 54: Train set: Average loss: 0.0001, Accuracy: 59747/60000 (99.58%)\n",
      "Epoch = 55: Train set: Average loss: 0.0001, Accuracy: 59710/60000 (99.52%)\n",
      "Epoch = 56: Train set: Average loss: 0.0001, Accuracy: 59739/60000 (99.56%)\n",
      "Epoch = 57: Train set: Average loss: 0.0001, Accuracy: 59718/60000 (99.53%)\n",
      "Epoch = 58: Train set: Average loss: 0.0001, Accuracy: 59723/60000 (99.54%)\n",
      "Epoch = 59: Train set: Average loss: 0.0001, Accuracy: 59724/60000 (99.54%)\n",
      "Epoch = 60: Train set: Average loss: 0.0001, Accuracy: 59731/60000 (99.55%)\n",
      "Epoch = 61: Train set: Average loss: 0.0001, Accuracy: 59747/60000 (99.58%)\n",
      "Epoch = 62: Train set: Average loss: 0.0001, Accuracy: 59785/60000 (99.64%)\n",
      "Epoch = 63: Train set: Average loss: 0.0001, Accuracy: 59771/60000 (99.62%)\n",
      "Epoch = 64: Train set: Average loss: 0.0001, Accuracy: 59759/60000 (99.60%)\n",
      "Epoch = 65: Train set: Average loss: 0.0001, Accuracy: 59799/60000 (99.67%)\n",
      "Epoch = 66: Train set: Average loss: 0.0001, Accuracy: 59801/60000 (99.67%)\n",
      "Epoch = 67: Train set: Average loss: 0.0001, Accuracy: 59810/60000 (99.68%)\n",
      "Epoch = 68: Train set: Average loss: 0.0001, Accuracy: 59790/60000 (99.65%)\n",
      "Epoch = 69: Train set: Average loss: 0.0001, Accuracy: 59815/60000 (99.69%)\n",
      "Epoch = 70: Train set: Average loss: 0.0001, Accuracy: 59752/60000 (99.59%)\n",
      "Epoch = 71: Train set: Average loss: 0.0001, Accuracy: 59832/60000 (99.72%)\n",
      "Epoch = 72: Train set: Average loss: 0.0001, Accuracy: 59834/60000 (99.72%)\n",
      "Epoch = 73: Train set: Average loss: 0.0001, Accuracy: 59827/60000 (99.71%)\n",
      "Epoch = 74: Train set: Average loss: 0.0001, Accuracy: 59825/60000 (99.71%)\n",
      "Epoch = 75: Train set: Average loss: 0.0001, Accuracy: 59839/60000 (99.73%)\n",
      "Epoch = 76: Train set: Average loss: 0.0001, Accuracy: 59833/60000 (99.72%)\n",
      "Epoch = 77: Train set: Average loss: 0.0001, Accuracy: 59827/60000 (99.71%)\n",
      "Epoch = 78: Train set: Average loss: 0.0001, Accuracy: 59828/60000 (99.71%)\n",
      "Epoch = 79: Train set: Average loss: 0.0001, Accuracy: 59869/60000 (99.78%)\n",
      "Epoch = 80: Train set: Average loss: 0.0001, Accuracy: 59828/60000 (99.71%)\n",
      "Epoch = 81: Train set: Average loss: 0.0001, Accuracy: 59873/60000 (99.79%)\n",
      "Epoch = 82: Train set: Average loss: 0.0001, Accuracy: 59872/60000 (99.79%)\n",
      "Epoch = 83: Train set: Average loss: 0.0001, Accuracy: 59845/60000 (99.74%)\n",
      "Epoch = 84: Train set: Average loss: 0.0001, Accuracy: 59837/60000 (99.73%)\n",
      "Epoch = 85: Train set: Average loss: 0.0001, Accuracy: 59834/60000 (99.72%)\n",
      "Epoch = 86: Train set: Average loss: 0.0001, Accuracy: 59852/60000 (99.75%)\n",
      "Epoch = 87: Train set: Average loss: 0.0001, Accuracy: 59850/60000 (99.75%)\n",
      "Epoch = 88: Train set: Average loss: 0.0001, Accuracy: 59877/60000 (99.80%)\n",
      "Epoch = 89: Train set: Average loss: 0.0001, Accuracy: 59863/60000 (99.77%)\n",
      "Epoch = 90: Train set: Average loss: 0.0000, Accuracy: 59875/60000 (99.79%)\n",
      "Epoch = 91: Train set: Average loss: 0.0000, Accuracy: 59890/60000 (99.82%)\n",
      "Epoch = 92: Train set: Average loss: 0.0001, Accuracy: 59865/60000 (99.78%)\n",
      "Epoch = 93: Train set: Average loss: 0.0000, Accuracy: 59899/60000 (99.83%)\n",
      "Epoch = 94: Train set: Average loss: 0.0001, Accuracy: 59865/60000 (99.78%)\n",
      "Epoch = 95: Train set: Average loss: 0.0000, Accuracy: 59888/60000 (99.81%)\n",
      "Epoch = 96: Train set: Average loss: 0.0000, Accuracy: 59895/60000 (99.83%)\n",
      "Epoch = 97: Train set: Average loss: 0.0001, Accuracy: 59877/60000 (99.80%)\n",
      "Epoch = 98: Train set: Average loss: 0.0000, Accuracy: 59897/60000 (99.83%)\n",
      "Epoch = 99: Train set: Average loss: 0.0001, Accuracy: 59853/60000 (99.75%)\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "length = len(train_feeder.dataset)\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for inputs, labels in train_feeder:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad() # refresh the buffer\n",
    "        outputs = net(inputs) # forward\n",
    "        loss = criterion(outputs, labels) # calculate the loss\n",
    "        loss.backward() # BP\n",
    "        optimizer.step() # p' = p - lr * grad\n",
    "        running_loss += loss.item()\n",
    "        pred = outputs.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        running_correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    running_loss /= length\n",
    "    \n",
    "    print('Epoch = {}: Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        epoch, running_loss, running_correct, length,100. * running_correct / length)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9875/10000 (98.75%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "length = len(test_feeder.dataset)\n",
    "with torch.no_grad():\n",
    "    for data, target in test_feeder:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = net(data)\n",
    "        test_loss += criterion(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= length\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "    test_loss, test_correct, length, 100. * test_correct / length))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
