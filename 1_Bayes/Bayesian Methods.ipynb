{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Methods\n",
    "\n",
    "> 张蔚桐   Weitong Zhang    2015011493    zwt15@mails.tsinghua.edu.cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLE and MAP\n",
    "\n",
    "1. MLE for the uniform distribution\n",
    "\n",
    "    1. \n",
    "    \n",
    "    Consider $l(\\theta) = \\sum_{i=1}^n\\log f(x_i|\\theta)$, to make $l(\\theta) > -\\infty, f(x_i|\\theta) > 0$, therefore, we get $a \\ge \\max |x_i|$. \n",
    "    \n",
    "    In this case, $l(\\theta) = \\frac{n}{2a}\\le \\frac{n}{2\\max |x_i|}$, where $\\hat a = \\max |x_i|$\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    - \n",
    "    \n",
    "    $$\\begin{cases}\n",
    "    0\\text{ , if  } |x_{n+1}| > \\hat a\\\\\n",
    "    \\frac 1 {2\\hat a} \\text{ , if else} \\end{cases}$$\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    - \n",
    "    \n",
    "    Consider $x_1 \\le x_2 \\le \\cdots \\le x_n$, we can find out that the $\\hat a$ is only related to $x_1,x_n$, that is to say, the information of $x_2,\\cdots,x_{n-1}$ is wasted. Meanwhile, if the dataset has some data which is error or rare, for example, a very big $x_n$, the $\\hat a$ is easily influenced by this point, in a few words, the model is too sensitive to the singular input.\n",
    "    \n",
    "    It is better to use other method, such as method of moments to get $\\hat a$, for instance, taking the following equation into cosideration:\n",
    "    \n",
    "    $$\\mathrm {Var}(X) \\approx \\frac{a^2}{3} \\Rightarrow \\hat a = \\sqrt{3\\mathrm {Var}(X)}$$ where $\\mathrm {Var}(X)$ is the variance of all of the data provided\n",
    "    \n",
    "    OR, another approach is to reshape the PDF into a relatively smooth function, for example, instead of the incontinuous function function, use the following function might seems to be a good idea:\n",
    "    \n",
    "    $$f(x) = C(\\mathrm{sigmoid}(a-|x|))/a,   \\mathrm{sigmoid}(x) = \\frac{1}{1+\\exp(-\\sigma x)}$$\n",
    "    \n",
    "    where $\\sigma$ might be determined manually, $C$ should be a constant for normalization, in this case, the MLE method should also be OK\n",
    "<br></br>\n",
    "<br></br>\n",
    "- MLE for model $t = y(x,\\mathbf w) + \\epsilon$\n",
    "\n",
    "    1. \n",
    "    \n",
    "    $p(\\mathbf T|\\mathbf X,\\mathbf w,\\beta) = \\prod \\sqrt{\\frac{\\beta}{2\\pi}}\\exp(-0.5\\beta(t_n - y(x_n,\\mathbf w))^2) $, therefore, we get $l(\\mathbf w) = n\\log\\sqrt{\\frac\\beta{2\\pi}} - 0.5\\beta \\sum (t_n - y(x_n,\\mathbf w))^2$. It is obvious that $\\max l(\\mathbf w) \\Leftrightarrow \\min \\sum (t_n - y(x_n,\\mathbf w))^2$, which is equivalent to the problem of minimizing the sum of the square error\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    - \n",
    "    \n",
    "    Taking the MAP method into consideration: $\\max l(\\theta) + \\log p(\\theta)$, therefore we got the objective function is that: $q(\\mathbf w ) = n\\log\\sqrt{\\frac\\beta{2\\pi}} - 0.5\\beta \\sum (t_n - y(x_n,\\mathbf w))^2 + \\frac{\\alpha}{\\sqrt{2\\pi}} -0.5 \\alpha (\\mathbf w)^2$, we can find out that $\\max q(\\mathbf w) \\Leftrightarrow \\min \\beta \\sum (t_n - y(x_n,\\mathbf w))^2 + \\alpha (\\mathbf w)^2 \\Leftrightarrow \\min 0.5\\sum (t_n - y(x_n,\\mathbf w))^2 + 0.5\\frac\\alpha\\beta (\\mathbf w)^2$, by set $\\lambda = \\frac \\alpha \\beta$, we can conclude that $\\max q(\\mathbf w) \\Leftrightarrow \\min E(\\mathbf w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Naive Bayes Method\n",
    "\n",
    "1.  \n",
    "\n",
    "    For each continuous variables, we can determine the $p(X_i|y_j) \\sim N(\\mu_{ij},\\sigma^2_{ij}) $ through the MLE method, we can also get the following matrix through MLE method:\n",
    "    $$ \\begin{pmatrix} P(X_1 = 0 | Y_1 = 0) & P(X_1 = 1 | Y_1 = 0) \\\\ P(X_1 = 0 | Y_1 = 1) & P(X_1 = 1 | Y_1 = 1) \\end{pmatrix} = \\begin{pmatrix} p_{11} & 1-p_{11} \\\\ p_{12} & 1-p_{12} \\end{pmatrix}$$\n",
    "\n",
    "    In this way, we can calc: $$P(Y|X) = \\frac{P(X|Y)P(Y)}{P(X|Y=0)P(Y=0)+P(X|Y=1)P(Y=1)} = \\frac{P(Y)\\prod P(x_i|Y)}{\\sum P(Y)\\prod P(x_i|Y)}$$\n",
    "\n",
    "    The $P(x_i|Y)$ are listed above, therefore, we have to determine $2 + 4(n-1) = 4n-2$ parameters to get the classfier\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "\n",
    "-  \n",
    "\n",
    "    1. $P(Hike|Sunny,Windy) = \\frac{P(Synny,Windy|Hike)P(Hike)}{Const.} = \\frac{P(Sunny|Hike)P(Windy|Hike)P(Hike)}{Const.}$\n",
    "    \n",
    "    $P(Hike|Sunny,\\neg Windy) = \\frac{P(Synny,Windy|\\neg Hike)P(\\neg Hike)}{Const.} = \\frac{P(Sunny|\\neg Hike)P(Windy|\\neg Hike)P(\\neg Hike)}{Const.}$ \n",
    "    \n",
    "    Therefore, we can get the $Const. = P(Sunny|\\neg Hike)P(Windy|\\neg Hike)P(\\neg Hike) + P(Sunny|Hike)P(Windy|Hike)P(Hike)$\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    - $P(e) = P(x\\in \\mathcal R_1,w_2) + P(x\\in \\mathcal R_2, w_1) $, we got the decision matrix as below:\n",
    "    \n",
    "    $$\\begin{pmatrix} & Sunny = T & Sunny = F\\\\ Windy = T & \\neg Hike & \\neg Hike \\\\ Windy = F & Hike & \\neg Hike \\end{pmatrix} $$ \n",
    "    \n",
    "    We can further more get the error rate as following:\n",
    "    \n",
    "    $$P(e) = P(Sunny,Windy,Hike) + P(\\neg Sunny,Windy,Hike) + P(Sunny,\\neg Windy,\\neg Hike) + P(\\neg Sunny,\\neg Windy,\\neg Hike)$$\n",
    "    \n",
    "    $$P(Sunny,Windy,Hike) = P(Sunny|Hiking)P(Windy|Hike)P(Hike) = 0.5 * 0.3 * 0.9 = 0.135$$\n",
    "    \n",
    "    $$P(\\neg Sunny,Windy,Hike) = P(\\neg Sunny|Hike)P(Windy|Hiking)P(Hike) = 0.5 * 0.3 * 0.1 = 0.015$$\n",
    "    \n",
    "    $$P(Sunny,\\neg Windy,\\neg Hike) = P(Sunny|\\neg Hike)P(\\neg Windy|\\neg Hike)P(\\neg Hike) = 0.5 * 0.2 * 0.4 = 0.004$$\n",
    "    \n",
    "    $$P(\\neg Sunny,\\neg Windy,Hike) = P(\\neg Sunny|Hike)P(\\neg Windy|Hike)P(Hike) = 0.5 * 0.7 * 0.1 = 0.035$$\n",
    "    \n",
    "    $P(e) = 0.135 + 0.015 + 0.004 + 0.035 = 0.189$, we can conclude that the error rate is about 18.9%\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    - $P(Sunny,Windy,Hike) = P(Sunny|Hiking)P(Windy|Hike)P(Hike) = 0.5 * 0.3 * 0.9 = 0.135$\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    - It is obvious that the basic assumptions of the Naive Bayes is violated. According to the basic assumption, the variables should be irrelevant, however, we can easily find out that $x_3 = \\neg x_1$, that is to say, $x_1$ can determine $x_3$. \n",
    "    \n",
    "    $P(Sunny,Windy,Hike) = P(Sunny|Hiking)P(Windy|Hike)P(Hike) = 0.5 * 0.3 * 0.9 = 0.135$\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    - We are considering Naive Bayes method, therefore, relationship between $x_1$ and $x_3$ is neglected. Therefore, we can get the following table for decision, in order to simplify our expressions, we set $P(T,T,T,T) \\triangleq P(x_1 = T,x_2 = T,x_3 = T,Y = T)$ and so on\n",
    "    \n",
    "    $$\\begin{cases}\n",
    "    P(T,T,T,T) = 0.5 * 0.9 * 0.3 * 0.1 = 0.0135,  P(T,T,T,F) = 0.5 * 0.4 * 0.8 * 0.6 = 0.096,  P(e) = 0.0135\\\\\n",
    "    P(T,T,F,T) = 0.5 * 0.9 * 0.3 * 0.9 = 0.1215,  P(T,T,F,F) = 0.5 * 0.4 * 0.8 * 0.4 = 0.064,  P(e) = 0.064\\\\ \n",
    "    P(T,F,T,T) = 0.5 * 0.9 * 0.7 * 0.1 = 0.0315,  P(T,F,T,F) = 0.5 * 0.4 * 0.2 * 0.6 = 0.024,  P(e) = 0.024\\\\\n",
    "    P(T,F,F,T) = 0.5 * 0.9 * 0.7 * 0.9 = 0.2835,  P(T,F,F,F) = 0.5 * 0.4 * 0.2 * 0.4 = 0.016,  P(e) = 0.016\\\\\n",
    "    P(F,T,T,T) = 0.5 * 0.1 * 0.3 * 0.1 = 0.0015,  P(F,T,T,F) = 0.5 * 0.6 * 0.8 * 0.6 = 0.144,  P(e) = 0.0015\\\\\n",
    "    P(F,T,F,T) = 0.5 * 0.1 * 0.3 * 0.9 = 0.0135,  P(F,T,F,F) = 0.5 * 0.6 * 0.8 * 0.4 = 0.096,  P(e) =  0.0135\\\\ \n",
    "    P(F,F,T,T) = 0.5 * 0.1 * 0.7 * 0.1 = 0.0035,  P(F,F,T,F) = 0.5 * 0.6 * 0.2 * 0.6 = 0.036,  P(e) = 0.0035\\\\\n",
    "    P(F,F,F,T) = 0.5 * 0.1 * 0.7 * 0.9 = 0.0315,  P(F,F,F,F) = 0.5 * 0.6 * 0.2 * 0.4 = 0.024,  P(e) =  0.024\n",
    "    \\end{cases}$$\n",
    "    \n",
    "    Therefore, we get $P(e) = 0.0135 + 0.064 + 0.024 + 0.016 + 0.0015 + 0.0135 + 0.0035 + 0.024 = 0.16$, it seems that there is a drop of error rate in contract with the original one, which is simply because we have just calc the 'Sunny' twice. However, this drop is useless, for the reason that the event such as $P(T,*,T,*), P(F,*,F,*)$ is impossible. Therefore, we should use the original method to calc the error rate.\n",
    "    \n",
    "    We found that the decision matrix have changed to the following state:\n",
    "    \n",
    "    $$\\begin{pmatrix} & Sunny = T & Sunny = F\\\\ Windy = T & Hike & \\neg Hike \\\\ Windy = F & Hike & \\neg Hike \\end{pmatrix} $$\n",
    "    \n",
    "    It is obvious that by the increasing weight of 'Sunnny', the 'Windy' variable is useless. Therefore, the error rate should be described as\n",
    "    \n",
    "    $$P(e) = P(Sunny,\\neg Hike) + P(\\neg Sunny, Hike) = 0.5 * (0.4 + 0.1) = 0.25$$\n",
    "    \n",
    "    It is a little greater than the original one. This is because we have just violate the fundamental assumptions of the Naive Bayes sharply.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes method\n",
    "\n",
    "#### Estimate  $\\theta_{y,i}$\n",
    "\n",
    "We use the MLE method to extimate $\\theta_{y_i}$, for a certain class of $y$, we can probability of the current state is \n",
    "\n",
    "$$ P(\\theta_y) = \\prod_x\\prod_{i=1}^m\\theta_{y,i}^{count_i(x)}, \\ln P(\\theta_y) = \\sum_x\\sum_{i=1}^mcount_i(x)\\ln{\\theta_{y,i}}$$ With the limit: $\\sum_{i=1}^m\\theta_{y,i} = 1$, therefore, we maximize the $\\ln P(\\theta_y)$ using the Lagrange Multiplier Method:\n",
    "\n",
    "$$\\max Q(\\theta_y) = \\sum_x\\sum_{i=1}^mcount_i(x)\\ln{\\theta_{y,i}} - \\lambda(\\sum_{i=1}^m\\theta_{y,i} - 1)$$\n",
    "\n",
    "$$\\frac{\\partial Q}{\\partial \\theta_{y,i} } =\\sum_x \\frac{count_i(x)}{\\theta_{y,i}} - \\lambda = 0 \\Rightarrow \\theta_{y,i} = \\sum_x \\frac{count_i(x)}{\\lambda}$$\n",
    "\n",
    "According to the limitation function, we got\n",
    "\n",
    "$$\\hat \\theta_{y,i} = \\frac{\\sum_x count_i(x)}{\\sum_i \\sum_x count_i(x)}$$\n",
    "\n",
    "From the following question, we can know that the estimation of $\\theta_{y,i}$ should finally be described as:\n",
    "\n",
    "$$\\hat \\theta_{y,i} = \\frac{\\sum_x count_i(x) + 1}{\\sum_i \\sum_x count_i(x) + m}$$\n",
    "\n",
    "which is called [add-one smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)\n",
    "\n",
    "#### Classify a new example:\n",
    "\n",
    "According to the Naive Bayes Method, we got $P(Y|X) = P(X|Y)P(Y)/P(X)$, therefore, to get the new example, we can easily determine the class of $y$ by calc $$y_{predict} = argmax(P(X|Y)P(Y)) = argmax(\\ln P(y)+\\sum_{i=1}^m count_i(x)\\ln \\theta_{y,i})$$\n",
    "\n",
    "where $P(y)$ should be determined from the training data set\n",
    "\n",
    "#### Facing a new word\n",
    "\n",
    "If we use the basic estimation of $\\theta_{y,i}$, that is $\\hat \\theta_{y,i} = \\frac{\\sum_x count_i(x)}{\\sum_i \\sum_x count_i(x)}$, we can found a newly introduced word in the testing data set got a $\\hat\\theta_{y,i} = 0$, in this case, the classifier based on the log function will produce an error (we choose the log function to accelerate the calc process). Moreorver, the $P(X|Y)$ will be stuck to 0, which makes other information provided by the document is waste.\n",
    "\n",
    "To avoid this problem, we use the [add-one smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) method to make the $\\theta_{y_i}$ a little bit greater than zero. However, this problem still exists that a probability near to zero can also nullify the other information. Therefore, in order to avoid this problem better, we can ignore the word which is never presented in the training data, which can also reserve the other information and can provide a better result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We are considering the object function described above:\n",
    "\n",
    "$$Q = \\ln P(y)+\\sum_{i=1}^m count_i(x)\\ln \\theta_{y,i}$$\n",
    "\n",
    "Instead of estimating the $\\ln P(y)$ and $\\ln\\theta_{y,i}$ by some statistical method, we just set them into parameters $\\mathbf w$ and $b$, therefore, we are considering maximizing the following function.\n",
    "\n",
    "$$ Q = b + \\mathbf w^T count(x)$$\n",
    "\n",
    "Which is also the same with maximizing the following function, which is equivalent to the $P(X|Y)P(Y)$\n",
    "\n",
    "$$\\exp(Q) = \\exp (b + \\mathbf w^T count(x))$$\n",
    "\n",
    "Then for all of the classes for this document, we desire the probability of the right class is 1 while other is 0, therefore, firstly, we write the equation above into matrix format, and then use a softmax to normialize it, which genereate a **Logistic Regression**. A softmax layer should be described as the following:\n",
    "\n",
    "$$y_i = \\frac{\\exp(x_i)}{\\sum_i\\exp(x_i)}$$\n",
    "\n",
    "The input of the logistic regression is the count matrix, and the output of the regression is the softmax encoding. We use the one-hot encoding to encode the label of the training document and train the regression.\n",
    "\n",
    "To classify a new example, we can calc the index of the max of the output of softmax layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming in practice\n",
    "\n",
    "#### Data reading in\n",
    "\n",
    "We use scipy to read in the sparse matrix data in `./dataset/train.data`, `./dataset/train.label`, `./dataset/test.data` and `./dataset/test.label`. In order to avoid unknown mistake, we set the indexing starting from 0 instead of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w_train = np.loadtxt('./dataset/train.data')\n",
    "w_test = np.loadtxt('./dataset/test.data')\n",
    "label_train = np.loadtxt('./dataset/train.label') - 1\n",
    "label_test = np.loadtxt('./dataset/test.label') - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:(11269, 53975), testing data shape: (7505, 61188)\n",
      "training label shape:(11269,), testing label shape: (7505,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "c_train = w_train[:,0] - 1\n",
    "r_train = w_train[:,1] - 1\n",
    "d_train = w_train[:,2]\n",
    "\n",
    "c_test = w_test[:,0] - 1\n",
    "r_test = w_test[:,1] - 1\n",
    "d_test = w_test[:,2]\n",
    "\n",
    "data_train = coo_matrix((d_train,(c_train,r_train))).todense()\n",
    "data_test = coo_matrix((d_test,(c_test,r_test))).todense()\n",
    "print ('training data shape:{}, testing data shape: {}'.format(data_train.shape,data_test.shape))\n",
    "print ('training label shape:{}, testing label shape: {}'.format(label_train.shape,label_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding that there are some words not presented in the training data, we have to cut off them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:(11269, 53975), testing data shape: (7505, 53975)\n",
      "training label shape:(11269,), testing label shape: (7505,)\n"
     ]
    }
   ],
   "source": [
    "data_test = data_test[:,0:data_train.shape[1]]\n",
    "print ('training data shape:{}, testing data shape: {}'.format(data_train.shape,data_test.shape))\n",
    "print ('training label shape:{}, testing label shape: {}'.format(label_train.shape,label_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "We carried out an Logistic Regression based on sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 99.885%, test accuracy: 75.190%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = linear_model.LogisticRegression()\n",
    "classifier.fit(data_train, label_train)\n",
    "train_predict = classifier.predict(data_train)\n",
    "train_accuracy = accuracy_score(label_train,train_predict)\n",
    "test_predict = classifier.predict(data_test)\n",
    "test_accuracy = accuracy_score(label_test,test_predict)\n",
    "\n",
    "print ('Train accuracy: {:.3f}%, test accuracy: {:.3f}%'.format(100 * train_accuracy,100 * test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "\n",
    "Firstly, we have to calc to $P(Y)$ and $\\hat\\theta_{y,i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_number = int(np.max(label_train)) + 1\n",
    "word_number = data_train.shape[1]\n",
    "sample_number = data_train.shape[0]\n",
    "P = np.zeros(class_number)\n",
    "\n",
    "for i in label_train:\n",
    "    P[int(i)] = P[int(i)] + 1\n",
    "\n",
    "P = P / len(label_train)\n",
    "\n",
    "count = np.zeros((class_number,word_number))\n",
    "\n",
    "for i in range(sample_number):\n",
    "    count[int(label_train[i]),:] = count[int(label_train[i]),:] + data_train[i,:]\n",
    "\n",
    "theta = count + 1\n",
    "sum_count = np.sum(count,axis=1) + word_number\n",
    "\n",
    "for i in range(class_number):\n",
    "    theta[i,:] = theta[i,:] / sum_count[i]\n",
    "    \n",
    "lp = np.reshape(np.log(P),(class_number,1))\n",
    "lt = np.log(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are able to give the prediction about the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 94.330%, test accuracy: 78.468%\n"
     ]
    }
   ],
   "source": [
    "score = lp * np.ones((1,sample_number)) + lt * data_train.transpose()\n",
    "train_predict = np.argmax(score,axis=0)\n",
    "train_accuracy = accuracy_score(label_train,np.array(train_predict.transpose()))\n",
    "\n",
    "test_number = data_test.shape[0]\n",
    "score = lp * np.ones((1,test_number)) + lt * data_test.transpose()\n",
    "test_predict = np.argmax(score,axis=0)\n",
    "test_accuracy = accuracy_score(label_test,np.array(test_predict.transpose()))\n",
    "\n",
    "print ('Train accuracy: {:.3f}%, test accuracy: {:.3f}%'.format(100 * train_accuracy,100 * test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison and Conclusion\n",
    "\n",
    "Finally we get the test accuracy and the train accuracy from the Logistic Regression and Naive Bayes are listed as following:\n",
    "\n",
    "|    | training accuracy | testing accuracy |\n",
    "| ---- | ---- | ---- |\n",
    "| N.B. Method| 94.3% | 78.468%|\n",
    "| L.R. Method|99.885%| 75.190%|\n",
    "\n",
    "It is obvious that the Logistic Regression is suggesting an overfitting, which means higher training accuracy and lower testing accuracy. Though according to the analysis above, these two method are the theoretically same to each other, Logistic Regression method tend to overfit the data set by iteration, while Naive Bayes are limited to a certain extent according to the Bayes Method.\n",
    "\n",
    "However, we have to point out that it is not always true that the overfitting does harm to the prediction. In our problem, the training data set and the testing data set are not so similiar (even have more words which does not appear in the training data), otherwise, the testing accuracy might be possible to be a little bit higher.\n",
    "\n",
    "In conclusion, the Naive Bayes method perform better in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes and problems\n",
    "\n",
    "> Here are some notes irrelevant to the original problems and just for myself to keep a record of the developping process\n",
    "\n",
    "There are surprisingly 2 kinds of Logistic Regression (or Linear Regression ? to be determined) in the sklearn, the other one can be looked up in the doc by searching SGD, which might be lack of a softmax layer, the proformance of the later one is worse than the original one\n",
    "\n",
    "At first, I thought the normalization of the data set is better. however, the performance of the Logistic Regression is drop to less than 20%, but I dont know why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
