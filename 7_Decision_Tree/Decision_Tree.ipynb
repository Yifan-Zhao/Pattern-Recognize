{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data read in and Train-Test split\n",
    "\n",
    "The train-test split have been implemented in the `main` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import deque\n",
    "\n",
    "matfile = sio.loadmat('./Sogou_data/Sogou_webpage.mat')\n",
    "label = matfile['doclabel']\n",
    "feature = matfile['wordMat']\n",
    "\n",
    "data = np.concatenate((feature,label), axis=1)\n",
    "np.random.shuffle(data)\n",
    "train_data = data[:int(0.6*data.shape[0]),:]\n",
    "valid_data = data[int(0.6*data.shape[0]):int(0.8*data.shape[0]),:]\n",
    "test_data = data[int(0.8*data.shape[0]):,:]\n",
    "\n",
    "train = {'feature':None,'label':None}\n",
    "valid = {'feature':None,'label':None}\n",
    "test = {'feature':None,'label':None}\n",
    "\n",
    "for pair in [[train_data,train],[valid_data,valid],[test_data,test]]:\n",
    "    pair[1]['feature'] = pair[0][:,:-1]\n",
    "    pair[1]['label'] = pair[0][:,-1]\n",
    "labels = np.linspace(1,9,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impurity Function\n",
    "\n",
    "Here, we implemented two functions to measure the impurity of dataset, which is \n",
    "\n",
    "$$\\text{Information Entropy:   } E = -\\sum_iP_i\\log_2P_i \\text{   Gini impurity:   } G = 1 - \\sum_iP_i^2$$\n",
    "\n",
    "In order to calc the $\\lim_{P\\to0}P\\log_2P$ correctly, we calc the $\\lim_{P\\to0}P\\log_2(P+eps) \\approx \\lim_{P\\to0}P\\log_2P$ instead, $eps = 1\\times 10 ^{-6}$. In this way, the calculation could be implemented easily by operations to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Impurity(samples, style='entropy'):\n",
    "    eps = 1e-6\n",
    "    P = np.zeros(labels.shape[0])\n",
    "    for i in range(labels.shape[0]):\n",
    "        P[i] = np.sum(samples == labels[i])\n",
    "    P = P / samples.shape[0]\n",
    "    if style == 'entropy':\n",
    "        return -np.sum(P * np.log2(P + eps))\n",
    "    elif style == 'gini':\n",
    "        return 1 - np.sum(P * P)\n",
    "    else:\n",
    "        raise ('No impurity style called '+ style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Class\n",
    "\n",
    "Here we implemented the `SelectFeature` function and `SplitNode` function. Based on these two function, we implemented the `GenerateTree` function. The stopping branching criteria could be described as the following:\n",
    "\n",
    "- All of the features is the same OR\n",
    "- The increasing of information gain (that is the decreasing of the impurity) provided by branching is smaller than the `thresh`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = deque()\n",
    "class node:\n",
    "    def __init__(self,data_feature,data_label,style='entropy',thresh=0.01, isleft=False, parent = None):\n",
    "        self.thresh = thresh\n",
    "        self.style = style\n",
    "        self.data = {'feature': data_feature,'label': data_label}\n",
    "        self.isleft = isleft\n",
    "        self.parent = parent\n",
    "        self.im = Impurity(self.data['label'],self.style)\n",
    "        self.label = stats.mode(self.data['label'])\n",
    "        \n",
    "        self.l = None\n",
    "        self.r = None\n",
    "        self.feature = None\n",
    "        self.valid_idx = None\n",
    "        \n",
    "    def SelectFeature(self):\n",
    "        imp = np.zeros(self.data['feature'].shape[1])\n",
    "        for f in range(self.data['feature'].shape[1]):\n",
    "            label_left = self.data['label'][self.data['feature'][:,f] == 0]\n",
    "            label_right = self.data['label'][self.data['feature'][:,f] == 1]\n",
    "            if np.sum(label_left) == 0 or np.sum(label_right) == 0:\n",
    "                imp[f] = np.infty\n",
    "            else:\n",
    "                imp[f] = label_left.shape[0] * Impurity(label_left,self.style) + label_right.shape[0] * Impurity(label_right,self.style)\n",
    "\n",
    "        self.feature = np.argmin(imp)\n",
    "        return imp[self.feature] / (label_left.shape[0] +  label_right.shape[0])\n",
    "    \n",
    "    def SplitNode(self):\n",
    "        idx_left = self.data['feature'][:,self.feature] == 0\n",
    "        idx_right = self.data['feature'][:,self.feature] == 1\n",
    "        self.l = node(self.data['feature'][idx_left,:], self.data['label'][idx_left],self.style, self.thresh,True,self)\n",
    "        self.r = node(self.data['feature'][idx_right,:], self.data['label'][idx_right],self.style, self.thresh,False,self)\n",
    "        \n",
    "    def GenerateTree(self):\n",
    "        next_step_im = self.SelectFeature()\n",
    "        if self.im - next_step_im > self.thresh:\n",
    "            self.SplitNode()\n",
    "            self.l.GenerateTree()\n",
    "            self.r.GenerateTree()\n",
    "            if self.l.l is None and self.l.r is None and self.r.l is None and self.r.r is None:\n",
    "                Q.append(self)     \n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building The tree\n",
    "\n",
    "We can build up the tree from the root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build(data,style,thres):\n",
    "    Q.clear()\n",
    "    root = node(data['feature'],data['label'],style,thres + 1e-6)# abvoid to provide a real 0\n",
    "    root.GenerateTree()\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "Here, we implement the `Decision` function as the following code. The `main_decision` is used to integrate the testing and output the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision(GeneratedTree,XToBePredited):\n",
    "    root = GeneratedTree\n",
    "    while root.l is not None and root.r is not None:\n",
    "        if XToBePredited[root.feature] == 0:\n",
    "            root = root.l\n",
    "        else:\n",
    "            root = root.r\n",
    "    return root.label[0][0]\n",
    "\n",
    "def main_decision(GeneratedTree, data_set, message=''):\n",
    "    predict = np.zeros_like(data_set['label'])\n",
    "    for idx in range(predict.shape[0]):\n",
    "        predict[idx] = Decision(GeneratedTree,data_set['feature'][idx,:])   \n",
    "    acc = (predict == data_set['label'])\n",
    "    print ('{}{:.1f}%'.format(message,sum(acc) / acc.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precolate and Punning\n",
    "\n",
    "We use the method described in the guide to punning the tree:\n",
    "\n",
    "First of all, we percolate all of the samples of the validation samples to all of the leaf node of the decision tree. And for each node which has two leaf nodes, we are trying to punning its children and check if the validation samples in its children node been correct classified.\n",
    "\n",
    "This loop is continuing until none of the node which have two leaf nodes satisified the criteria above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Percolate(GeneratedTree, features, labels):\n",
    "    root = GeneratedTree\n",
    "    root.valid_idx = np.ones_like(labels,dtype=np.bool)\n",
    "    queue = deque()\n",
    "    queue.append(root)\n",
    "    while queue:\n",
    "        p = queue.popleft()\n",
    "        if p.l is not None and p.r is not None:\n",
    "            queue.append(p.l)\n",
    "            queue.append(p.r)\n",
    "            p.l.valid_idx = np.bitwise_and(features[:,p.feature] == 0, p.valid_idx)\n",
    "            p.r.valid_idx = np.bitwise_and(features[:,p.feature] == 1, p.valid_idx)\n",
    "    return GeneratedTree\n",
    "\n",
    "def Punning(GeneratedTree, CrossValidationDataset):\n",
    "    correct = 0\n",
    "    GT = Percolate(GeneratedTree,CrossValidationDataset['feature'],CrossValidationDataset['label'])\n",
    "    while Q:\n",
    "        p = Q.popleft()\n",
    "        error_child = np.sum(CrossValidationDataset['label'][p.l.valid_idx] != p.l.label) + \\\n",
    "            np.sum(CrossValidationDataset['label'][p.r.valid_idx] != p.r.label)\n",
    "        error_parent = np.sum(CrossValidationDataset['label'][p.valid_idx] != p.label)\n",
    "        if error_parent < error_child:\n",
    "            correct += error_child - error_parent\n",
    "            # punning:\n",
    "            p.l = None\n",
    "            p.r = None\n",
    "            if (p.isleft and p.parent.r is None) or ((not p.isleft) and p.parent.l is None):\n",
    "                Q.append(p.parent)\n",
    "    print ('Punning: Correct about (less than) {:.1f}% of the samples on validation set'.format(\n",
    "        correct/CrossValidationDataset['label'].shape[0] * 100))\n",
    "    return GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum up and testing the hyper-parameter\n",
    "\n",
    "We test the threshold from 1e-3 to 1e-1 using two impurity method. The result is that\n",
    "\n",
    "- Using information entropy: `thres` = 1e-2 performs better: on testing dataset (after punning): 73.1%\n",
    "- Using gini impurity: `thres` = 1e-3 performs better: on testing dataset (after punning): 73.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Using entropy impurity, thres = 0.1 -----\n",
      "Using entropy impurity, thres = 0.1, before punning, on validation data set: 70.1%\n",
      "Using entropy impurity, thres = 0.1, before punning, on test data set: 69.6%\n",
      "Punning: Correct about (less than) 1.1% of the samples on validation set\n",
      "Using entropy impurity, thres = 0.1, after punning, on validation data set: 71.1%\n",
      "Using entropy impurity, thres = 0.1, after punning, on test data set: 69.7%\n",
      "---------- END ----------\n",
      "----- Using entropy impurity, thres = 0.01 -----\n",
      "Using entropy impurity, thres = 0.01, before punning, on validation data set: 71.4%\n",
      "Using entropy impurity, thres = 0.01, before punning, on test data set: 72.8%\n",
      "Punning: Correct about (less than) 1.8% of the samples on validation set\n",
      "Using entropy impurity, thres = 0.01, after punning, on validation data set: 73.1%\n",
      "Using entropy impurity, thres = 0.01, after punning, on test data set: 73.2%\n",
      "---------- END ----------\n",
      "----- Using entropy impurity, thres = 0.001 -----\n",
      "Using entropy impurity, thres = 0.001, before punning, on validation data set: 70.7%\n",
      "Using entropy impurity, thres = 0.001, before punning, on test data set: 72.0%\n",
      "Punning: Correct about (less than) 2.1% of the samples on validation set\n",
      "Using entropy impurity, thres = 0.001, after punning, on validation data set: 72.5%\n",
      "Using entropy impurity, thres = 0.001, after punning, on test data set: 72.5%\n",
      "---------- END ----------\n",
      "----- Using gini impurity, thres = 0.1 -----\n",
      "Using gini impurity, thres = 0.1, before punning, on validation data set: 9.8%\n",
      "Using gini impurity, thres = 0.1, before punning, on test data set: 11.0%\n",
      "Punning: Correct about (less than) 0.0% of the samples on validation set\n",
      "Using gini impurity, thres = 0.1, after punning, on validation data set: 9.8%\n",
      "Using gini impurity, thres = 0.1, after punning, on test data set: 11.0%\n",
      "---------- END ----------\n",
      "----- Using gini impurity, thres = 0.01 -----\n",
      "Using gini impurity, thres = 0.01, before punning, on validation data set: 73.9%\n",
      "Using gini impurity, thres = 0.01, before punning, on test data set: 74.1%\n",
      "Punning: Correct about (less than) 1.4% of the samples on validation set\n",
      "Using gini impurity, thres = 0.01, after punning, on validation data set: 75.0%\n",
      "Using gini impurity, thres = 0.01, after punning, on test data set: 74.3%\n",
      "---------- END ----------\n",
      "----- Using gini impurity, thres = 0.001 -----\n",
      "Using gini impurity, thres = 0.001, before punning, on validation data set: 72.9%\n",
      "Using gini impurity, thres = 0.001, before punning, on test data set: 72.6%\n",
      "Punning: Correct about (less than) 2.7% of the samples on validation set\n",
      "Using gini impurity, thres = 0.001, after punning, on validation data set: 75.4%\n",
      "Using gini impurity, thres = 0.001, after punning, on test data set: 73.2%\n",
      "---------- END ----------\n"
     ]
    }
   ],
   "source": [
    "def main(style,thres):\n",
    "    print ('----- Using {} impurity, thres = {} -----'.format(style,thres))\n",
    "    T = build(train,style,thres)\n",
    "    main_decision(T,valid,message='Using {} impurity, thres = {}, before punning, on validation data set: '.format(style,thres))\n",
    "    main_decision(T,test,message='Using {} impurity, thres = {}, before punning, on test data set: '.format(style,thres))\n",
    "    T = Punning(T,valid)\n",
    "    main_decision(T,valid,message='Using {} impurity, thres = {}, after punning, on validation data set: '.format(style,thres))\n",
    "    main_decision(T,test,message='Using {} impurity, thres = {}, after punning, on test data set: '.format(style,thres))\n",
    "    print ('---------- END ----------')\n",
    "\n",
    "for s in ['entropy','gini']:\n",
    "    for t in [1e-1,1e-2,1e-3]:\n",
    "        np.random.shuffle(data)\n",
    "        train_data = data[:int(0.6*data.shape[0]),:]\n",
    "        valid_data = data[int(0.6*data.shape[0]):int(0.8*data.shape[0]),:]\n",
    "        test_data = data[int(0.8*data.shape[0]):,:]\n",
    "\n",
    "        train = {'feature':None,'label':None}\n",
    "        valid = {'feature':None,'label':None}\n",
    "        test = {'feature':None,'label':None}\n",
    "\n",
    "        for pair in [[train_data,train],[valid_data,valid],[test_data,test]]:\n",
    "            pair[1]['feature'] = pair[0][:,:-1]\n",
    "            pair[1]['label'] = pair[0][:,-1]\n",
    "        main(s,t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
