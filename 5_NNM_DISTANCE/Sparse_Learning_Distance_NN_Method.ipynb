{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Learning, Distance and (k)NN method\n",
    "\n",
    "> Weitong Zhang\n",
    "> 2015011493\n",
    ">\n",
    "> <zwt15@mails.tsinghua.edu.cn>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voronor Gird in Euclid Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error rate of NN method\n",
    "\n",
    "### Error rate of Baysian Method\n",
    "\n",
    "Since the probability of $x \\in [0,\\frac{cr}{c-1}]$, the classifier could be only randomly chosen from all of the $c$ categories\n",
    "\n",
    "$$P^* = \\sum_i P(w_i)P_{err} = \\frac{cr}{c-1} \\times \\frac{c-1}{c} = r$$\n",
    "\n",
    "### Error rate of NN method\n",
    "\n",
    "Suppose that the number of samples in the training dataset is sufficient, i.e. for each $x$ where $p(x|w_i) \\ne 0$, there are enough samples belong to $w_i$\n",
    "\n",
    "For each $x\\in w_i$, if $x \\in [i,i+ 1 - \\frac{cr}{c-1}]$, the NN method will not generate error, if $x\\in [0,\\frac{cr}{c-1}]$, the nearest sample of $x$ belongs to all of the $c$ categories, therefore, the probability of error is $\\frac{c-1}{c}$\n",
    "\n",
    "Therefore, the error rate of NN method is \n",
    "\n",
    "$$\\frac{cr}{c-1} \\times \\frac{c-1}{c} = r = P^*$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minkowski Distance\n",
    "\n",
    "Minkowski distance should be described as:\n",
    "\n",
    "$$ D(X,Y) = (\\sum_i |x_i - y_i|^p )^{1/p}$$\n",
    "\n",
    "According to the definition of distance, a distance should obey the following rules:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "D(p,q) & \\ge 0, D(p,q) = 0 \\Leftrightarrow p = q\\\\\n",
    "D(p,q) &= D(q,p)\\\\\n",
    "D(p,q) &\\le D(p,z) + D(q,z)\n",
    "\\end{aligned}$$\n",
    "\n",
    "Owing to the fact that $|x| = |-x| \\ge 0, |x| = 0 \\Leftrightarrow x = 0$, the first two rules are easily satisfied. We are about to prove:\n",
    "\n",
    "$$ (\\sum_i |x_i + y_i|^p )^{1/p} \\le (\\sum_i |x_i|^p )^{1/p} + (\\sum_i |y_i|^p )^{1/p}$$\n",
    "\n",
    "$$ \\sum_i |x_i + y_i|^p = \\sum_i |x_i + y_i| \\times |x_i + y_i|^{p-1} \\le \\sum_i |x_i| \\times |x_i + y_i|^{p-1} + \\sum_i |y_i| \\times |x_i + y_i|^{p-1}$$\n",
    "\n",
    "Now, we have to use the $\\mathrm {H\\ddot older}$ inequation:\n",
    "\n",
    "$$\\sum_i u_iv_i \\le (\\sum u_i^p)^{\\frac1p}(v_i^q)^{\\frac1q}, \\text{ where } \\frac1p + \\frac1q = 1$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\\sum_i |x_i| \\times |x_i + y_i|^{p-1} \\le (\\sum_i |x_i|^p)^{\\frac1p}(\\sum_i|x_i + y_i|^{(p-1)q})^{\\frac1q}, \\text{ where } \\frac1p + \\frac1q = 1 \\Rightarrow pq - q = p$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\\sum_i |x_i| \\times |x_i + y_i|^{p-1} + \\sum_i |y_i| \\times |x_i + y_i|^{p-1} \\le (\\sum_i |x_i|^p)^{\\frac1p}(\\sum_i |x_i + y_i|^p)^{\\frac1q} + (\\sum_i |y_i|^p)^{\\frac1p}(\\sum_i |x_i + y_i|^p)^{\\frac1q}$$\n",
    "\n",
    "Therefore, since $\\frac1p + \\frac1q = 1$, we get\n",
    "\n",
    "$$\\begin{aligned}\n",
    "&\\sum_i |x_i + y_i|^p \\le ((\\sum_i |y_i|^p)^{\\frac1p} + (\\sum_i |x_i|^p)^{\\frac1p})(\\sum_i |x_i + y_i|^p)^{\\frac1q}\\\\\n",
    "&\\Leftrightarrow \\frac{\\sum_i |x_i + y_i|^p}{(\\sum_i |x_i + y_i|^p)^{\\frac1q}} \\le (\\sum_i |y_i|^p)^{\\frac1p} + (\\sum_i |x_i|^p)^{\\frac1p}\\\\\n",
    "&\\Leftrightarrow (\\sum_i |x_i + y_i|^p )^{1/p} \\le (\\sum_i |x_i|^p )^{1/p} + (\\sum_i |y_i|^p )^{1/p}\n",
    "\\end{aligned}$$\n",
    "\n",
    "The prove above use the [Hölder's inequality](https://en.wikipedia.org/wiki/Hölder%27s_inequality#Proof_of_Hölder's_inequality)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
