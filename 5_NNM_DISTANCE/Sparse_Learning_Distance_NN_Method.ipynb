{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Learning, Distance and (k)NN method\n",
    "\n",
    "> Weitong Zhang\n",
    "> 2015011493\n",
    ">\n",
    "> <zwt15@mails.tsinghua.edu.cn>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voronor Gird in Euclid Space\n",
    "\n",
    "We are about to prove the following statement:\n",
    "\n",
    "$$\\begin{cases}\n",
    "\\forall i\\ \\|\\vec x_i - \\vec s_1 \\|_2^2 \\ge \\|\\vec x_0 - \\vec s_1 \\|_2^2\\\\\n",
    "\\forall i\\ \\|\\vec x_i - \\vec s_2 \\|_2^2 \\ge \\|\\vec x_0 - \\vec s_2 \\|_2^2\\\\\n",
    "\\forall t\\ \\in [0,1], \\vec s = t\\vec s_1 + (1-t) \\vec s_2\n",
    "\\end{cases} \\Rightarrow \\forall i\\ \\|\\vec x_i - \\vec s \\|_2^2 \\ge \\|\\vec x_0 - \\vec s \\|_2^2\n",
    "$$\n",
    "\n",
    "$$\\begin{cases}\n",
    "\\|\\vec x_i - \\vec s \\|_2^2 - \\|\\vec x_0 - \\vec s \\|_2^2 = \\sum_j (x_{ij} - s_j)^2 - \\sum_j (x_{0j} - s_j)^2 = \\sum_j (x_{ij} - x_{0j})(x_{ij} + x_{0j} - 2s_j)\\\\\n",
    "\\|\\vec x_i - \\vec s_1 \\|_2^2 - \\|\\vec x_0 - \\vec s_1 \\|_2^2 = \\sum_j (x_{ij} - s_{1j})^2 - \\sum_j (x_{0j} - s_{1j})^2 = \\sum_j (x_{ij} - x_{0j})(x_{ij} + x_{0j} - 2s_{1j}) \\ge 0\\\\\n",
    "\\|\\vec x_i - \\vec s_2 \\|_2^2 - \\|\\vec x_0 - \\vec s_2 \\|_2^2 = \\sum_j (x_{ij} - s_{2j})^2 - \\sum_j (x_{0j} - s_{2j})^2 = \\sum_j (x_{ij} - x_{0j})(x_{ij} + x_{0j} - 2s_{2j}) \\ge 0\n",
    "\\end{cases}$$\n",
    "\n",
    "We can easily found out that the first inequation is the linear combination of the later two, therefore, \n",
    "\n",
    "$$ \\begin{aligned}\n",
    "\\|\\vec x_i - \\vec s \\|_2^2 - \\|\\vec x_0 - \\vec s \\|_2^2 = \\sum_j (x_{ij} - s_j)^2 - \\sum_j (x_{0j} - s_j)^2 = \\sum_j (x_{ij} - x_{0j})(x_{ij} + x_{0j} - 2s_j) \\\\\n",
    "= t(\\sum_j (x_{ij} - x_{0j})(x_{ij} + x_{0j} - 2s_{1j})) + (1-t) (\\sum_j (x_{ij} - x_{0j})(x_{ij} + x_{0j} - 2s_{2j})) \\ge 0\n",
    "\\end{aligned}$$\n",
    "\n",
    "Therefore, the set determined by Voronoi is a convex set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error rate of NN method\n",
    "\n",
    "### Error rate of Baysian Method\n",
    "\n",
    "Since the probability of $x \\in [0,\\frac{cr}{c-1}]$, the classifier could be only randomly chosen from all of the $c$ categories\n",
    "\n",
    "$$P^* = \\sum_i P(w_i)P_{err} = \\frac{cr}{c-1} \\times \\frac{c-1}{c} = r$$\n",
    "\n",
    "### Error rate of NN method\n",
    "\n",
    "Suppose that the number of samples in the training dataset is sufficient, i.e. for each $x$ where $p(x|w_i) \\ne 0$, there are enough samples belong to $w_i$\n",
    "\n",
    "For each $x\\in w_i$, if $x \\in [i,i+ 1 - \\frac{cr}{c-1}]$, the NN method will not generate error, if $x\\in [0,\\frac{cr}{c-1}]$, the nearest sample of $x$ belongs to all of the $c$ categories, therefore, the probability of error is $\\frac{c-1}{c}$\n",
    "\n",
    "Therefore, the error rate of NN method is \n",
    "\n",
    "$$\\frac{cr}{c-1} \\times \\frac{c-1}{c} = r = P^*$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minkowski Distance\n",
    "\n",
    "Minkowski distance should be described as:\n",
    "\n",
    "$$ D(X,Y) = (\\sum_i |x_i - y_i|^p )^{1/p}$$\n",
    "\n",
    "According to the definition of distance, a distance should obey the following rules:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "D(p,q) & \\ge 0, D(p,q) = 0 \\Leftrightarrow p = q\\\\\n",
    "D(p,q) &= D(q,p)\\\\\n",
    "D(p,q) &\\le D(p,z) + D(q,z)\n",
    "\\end{aligned}$$\n",
    "\n",
    "Owing to the fact that $|x| = |-x| \\ge 0, |x| = 0 \\Leftrightarrow x = 0$, the first two rules are easily satisfied. We are about to prove:\n",
    "\n",
    "$$ (\\sum_i |x_i + y_i|^p )^{1/p} \\le (\\sum_i |x_i|^p )^{1/p} + (\\sum_i |y_i|^p )^{1/p}$$\n",
    "\n",
    "$$ \\sum_i |x_i + y_i|^p = \\sum_i |x_i + y_i| \\times |x_i + y_i|^{p-1} \\le \\sum_i |x_i| \\times |x_i + y_i|^{p-1} + \\sum_i |y_i| \\times |x_i + y_i|^{p-1}$$\n",
    "\n",
    "Now, we have to use the $\\mathrm {H\\ddot older}$ inequation:\n",
    "\n",
    "$$\\sum_i u_iv_i \\le (\\sum u_i^p)^{\\frac1p}(v_i^q)^{\\frac1q}, \\text{ where } \\frac1p + \\frac1q = 1$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\\sum_i |x_i| \\times |x_i + y_i|^{p-1} \\le (\\sum_i |x_i|^p)^{\\frac1p}(\\sum_i|x_i + y_i|^{(p-1)q})^{\\frac1q}, \\text{ where } \\frac1p + \\frac1q = 1 \\Rightarrow pq - q = p$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\\sum_i |x_i| \\times |x_i + y_i|^{p-1} + \\sum_i |y_i| \\times |x_i + y_i|^{p-1} \\le (\\sum_i |x_i|^p)^{\\frac1p}(\\sum_i |x_i + y_i|^p)^{\\frac1q} + (\\sum_i |y_i|^p)^{\\frac1p}(\\sum_i |x_i + y_i|^p)^{\\frac1q}$$\n",
    "\n",
    "Therefore, since $\\frac1p + \\frac1q = 1$, we get\n",
    "\n",
    "$$\\begin{aligned}\n",
    "&\\sum_i |x_i + y_i|^p \\le ((\\sum_i |y_i|^p)^{\\frac1p} + (\\sum_i |x_i|^p)^{\\frac1p})(\\sum_i |x_i + y_i|^p)^{\\frac1q}\\\\\n",
    "&\\Leftrightarrow \\frac{\\sum_i |x_i + y_i|^p}{(\\sum_i |x_i + y_i|^p)^{\\frac1q}} \\le (\\sum_i |y_i|^p)^{\\frac1p} + (\\sum_i |x_i|^p)^{\\frac1p}\\\\\n",
    "&\\Leftrightarrow (\\sum_i |x_i + y_i|^p )^{1/p} \\le (\\sum_i |x_i|^p )^{1/p} + (\\sum_i |y_i|^p )^{1/p}\n",
    "\\end{aligned}$$\n",
    "\n",
    "The prove above use the [Hölder's inequality](https://en.wikipedia.org/wiki/Hölder%27s_inequality#Proof_of_Hölder's_inequality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming\n",
    "\n",
    "### Getting the MNIST data\n",
    "\n",
    "In order to minimize the file to upload, we get the MNIST data from website each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import struct\n",
    "import sys\n",
    "try: \n",
    "    from urllib.request import urlretrieve \n",
    "except ImportError: \n",
    "    from urllib import urlretrieve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "def loadData(src, cimg):\n",
    "    print ('Downloading ' + src)\n",
    "    gzfname, h = urlretrieve(src, './delete.me')\n",
    "    try:\n",
    "        with gzip.open(gzfname) as gz:\n",
    "            n = struct.unpack('I', gz.read(4))\n",
    "            # Read magic number.\n",
    "            if n[0] != 0x3080000:\n",
    "                raise Exception('Invalid file: unexpected magic number.')\n",
    "            # Read number of entries.\n",
    "            n = struct.unpack('>I', gz.read(4))[0]\n",
    "            if n != cimg:\n",
    "                raise Exception('Invalid file: expected {0} entries.'.format(cimg))\n",
    "            crow = struct.unpack('>I', gz.read(4))[0]\n",
    "            ccol = struct.unpack('>I', gz.read(4))[0]\n",
    "            if crow != 28 or ccol != 28:\n",
    "                raise Exception('Invalid file: expected 28 rows/cols per image.')\n",
    "            # Read data.\n",
    "            res = np.frombuffer(gz.read(cimg * crow * ccol), dtype = np.uint8)\n",
    "    finally:\n",
    "        os.remove(gzfname)\n",
    "    return res.reshape((cimg, crow * ccol))\n",
    "\n",
    "def loadLabels(src, cimg):\n",
    "    print ('Downloading ' + src)\n",
    "    gzfname, h = urlretrieve(src, './delete.me')\n",
    "    try:\n",
    "        with gzip.open(gzfname) as gz:\n",
    "            n = struct.unpack('I', gz.read(4))\n",
    "            # Read magic number.\n",
    "            if n[0] != 0x1080000:\n",
    "                raise Exception('Invalid file: unexpected magic number.')\n",
    "            # Read number of entries.\n",
    "            n = struct.unpack('>I', gz.read(4))\n",
    "            if n[0] != cimg:\n",
    "                raise Exception('Invalid file: expected {0} rows.'.format(cimg))\n",
    "            # Read labels.\n",
    "            res = np.frombuffer(gz.read(cimg), dtype = np.uint8)\n",
    "    finally:\n",
    "        os.remove(gzfname)\n",
    "    return res.reshape((cimg, 1))\n",
    "\n",
    "def try_download(dataSrc, labelsSrc, cimg):\n",
    "    data = loadData(dataSrc, cimg)\n",
    "    labels = loadLabels(labelsSrc, cimg)\n",
    "    return data.astype(np.float32)/256.0,labels\n",
    "\n",
    "# URLs for the train image and label data\n",
    "url_train_image = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
    "url_train_labels = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
    "num_train_samples = 60000\n",
    "train_data,train_labels = try_download(url_train_image, url_train_labels, num_train_samples)\n",
    "\n",
    "# URLs for the test image and label data\n",
    "url_test_image = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
    "url_test_labels = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "num_test_samples = 10000\n",
    "test_data,test_labels = try_download(url_test_image, url_test_labels, num_test_samples)\n",
    "\n",
    "train_sum = 60000\n",
    "test_sum = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel of NN method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_nn(size=60000,k=5,p=2):\n",
    "    data_used, _, label_used, _ = train_test_split(train_data,train_labels,test_size = train_sum - size)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k,p=p,n_jobs=-1)\n",
    "    start = time.clock()\n",
    "    neigh.fit(data_used,np.ravel(label_used))\n",
    "    predict = neigh.predict(test_data)\n",
    "    end = time.clock()\n",
    "    return accuracy_score(test_labels,predict),end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The influence of number of samples on the performance of the classifier\n",
    "\n",
    "According to the algorithm, the space complexity is $\\mathcal O(n)$ (suppose the sort function could be done locally). The time complexity is $\\mathcal O(N\\log N) + \\mathcal O(Nd)$, where $N$ is the number of samples. $d$ is the dimension of the features.\n",
    "\n",
    "The accuracy of the classifier would keep increasing as the number of the samples increasing. However, the increasing rate would be slow down\n",
    "\n",
    "In this experiment, we set $k = 5$ and the distance function is euclid distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for samples in [6,60,600,6000,60000]:\n",
    "    p,t = main_nn(size=samples)\n",
    "    print('Samples = {}, Accuracy = {:.1f}%, TimeElapsed = {:e}s'.format(samples,p * 100,t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The influence of $k$ on the performance of the classifier\n",
    "\n",
    "We test $k = 1,3,5,7,9,11$ in the situation that number of samples is 6,000 to check the incluence of $k$ on the performance of the classifier. The distance function is still set to euclid function.\n",
    "\n",
    "As the result shows, the accuracy of the performance is not increasing, This might because the number of samples is too large, therefore, we do this experiment again setting the number of samples to 600.\n",
    "\n",
    "After setting the number of samples to 600, we can find out that the accuracy of the classifier is dropping, which might because the train set is too small, that the 11-th sample, 9-th sample are not belong to the same category of the testing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('In 6,000 samples: ')\n",
    "for k in [1,3,5,7,9,11]:\n",
    "    p,t = main_nn(size=6000,k=k)\n",
    "    print('k = {}, Accuracy = {:.1f}%, TimeElapsed = {:e}s'.format(k,p * 100,t))\n",
    "print('In 600 samples: ')    \n",
    "for k in [1,3,5,7,9,11]:\n",
    "    p,t = main_nn(size=600, k=k)\n",
    "    print('k = {}, Accuracy = {:.1f}%, TimeElapsed = {:e}s'.format(k,p * 100,t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different distance function\n",
    "\n",
    "We use minkowski distance, where $p = 1$ (Manhattan Distance), $p = 2$ (Euclid Distance, mentioned above),$p = \\infty$ (Chebyshev distance) to carry on this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in [1,2,float('inf')]:\n",
    "    p,t = main_nn(p=s)\n",
    "    print('p = {}, Accuracy = {:.1f}%, TimeElapsed = {:e}s'.format(s,p * 100,t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the weight for each element\n",
    "\n",
    "Our idea is to split the training dataset to validation dataset and training dataset, and use the validation dataset to correct the $\\vec a$, all of the algorithm is described below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_nn_with_a(size=60000):\n",
    "    data_used, _, label_used, _ = train_test_split(train_data,train_labels,test_size = train_sum - size)\n",
    "    A = np.zeros(28 * 28)\n",
    "    lr = 0.01\n",
    "    epoch = 1\n",
    "    batch_size = 5000\n",
    "    inner_iter = 10\n",
    "    for batch in range(epoch):\n",
    "        eA = 1.0 / (1 + np.exp(-A))\n",
    "        td,vd,tl,vl = train_test_split(train_data,train_labels,train_size = batch_size, test_size = batch_size)\n",
    "        for inner in range(inner_iter):\n",
    "            neigh = KNeighborsClassifier(n_neighbors=1,n_jobs=-1)\n",
    "            neigh.fit(td * eA,np.ravel(tl))\n",
    "            pre = neigh.kneighbors(vd * eA)[1]\n",
    "            pre_label = tl[pre]\n",
    "            nei = td[pre]\n",
    "            acc = 0\n",
    "            for i in range(batch_size):\n",
    "                delta = nei[i] - vd[i]\n",
    "                l = np.abs(delta) / np.linalg.norm(delta) / np.linalg.norm(delta)\n",
    "                #print (np.max(l))\n",
    "                if pre_label[i] != vl[i]: \n",
    "                    #print (np.max(l))\n",
    "                    A = A + lr * l \n",
    "                else:\n",
    "                    acc = acc + 1\n",
    "                    A = A - 1e-2 * lr * l\n",
    "#         if batch % 100 == 0:\n",
    "#             print ('Minibatch {}: accuracy: {:.1f}%, max A = {}'\n",
    "#                    .format(batch,acc / batch_size * 100, np.max(eA)))\n",
    "            \n",
    "    eA = 1.0 / (1 + np.exp(-A))\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1,n_jobs=-1)\n",
    "    start = time.clock()\n",
    "    neigh.fit(data_used * eA,np.ravel(label_used))\n",
    "    predict = neigh.predict(test_data * eA)\n",
    "    end = time.clock()\n",
    "    neigh_old = KNeighborsClassifier(n_neighbors=1,n_jobs=-1)\n",
    "    \n",
    "    start_old = time.clock()\n",
    "    neigh_old.fit(data_used,np.ravel(label_used))\n",
    "    predict_old = neigh_old.predict(test_data)\n",
    "    end_old = time.clock()\n",
    "    return accuracy_score(test_labels,predict),end-start, \\\n",
    "        accuracy_score(test_labels,predict_old),end_old-start_old, eA\n",
    "\n",
    "p,t,p_old,t_old,A = main_nn_with_a(size=60000)\n",
    "print('New: Accuracy = {:.1f}%, TimeElapsed = {:e}s\\tOld: Accuracy = {:.1f}%, TimeElapsed = {:e}s'\n",
    "      .format(p * 100,t,p_old * 100,t_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent distance on MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
